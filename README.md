<p align="center">
  
  <h3 align="center"><strong>GEAL: Generalizable 3D Affordance Learning with Cross-Modal Consistency</strong></h3>

  <p align="center">
      <a href="https://dylanorange.github.io" target='_blank'>Dongyue Lu</a>&nbsp;&nbsp;&nbsp;
      <a href="https://ldkong.com" target='_blank'>Lingdong Kong</a>&nbsp;&nbsp;&nbsp;
      <a href="https://tianxinhuang.github.io/" target='_blank'>Tianxin Huang</a>&nbsp;&nbsp;&nbsp;
      <a href="https://www.comp.nus.edu.sg/~leegh/">Gim Hee Lee</a>&nbsp;&nbsp;&nbsp;
    </br>
  National University of Singapore&nbsp;&nbsp;&nbsp;
  </p>

</p>

<p align="center">
  <a href="https://dylanorange.github.io/files/geal.pdf" target='_blank'>
    <img src="https://img.shields.io/badge/Paper-%F0%9F%93%83-lightblue">
  </a>
  <a href="https://dylanorange.github.io/projects/geal" target='_blank'>
    <img src="https://img.shields.io/badge/Project-%F0%9F%94%97-blue">
  </a>
  <a href="https://huggingface.co/datasets/dylanorange/geal" target="_blank">
    <img src="https://img.shields.io/badge/Dataset-%20Hugging%20Face-yellow">
  </a>
</p>



## About 🛠️

GEAL is a novel framework designed to enhance the generalization and robustness of 3D affordance learning by leveraging pre-trained 2D models. We employ a dual-branch architecture with Gaussian splatting to map 3D point clouds to 2D representations, enabling realistic renderings. Granularity-adaptive fusion and 2D-3D consistency alignment modules further strengthen cross-modal alignment and knowledge transfer, allowing the 3D branch to benefit from the rich semantics and generalization capacity of 2D models.



<div style="text-align: center;">
    <img src="docus/webpage.gif" alt="GEAL Performance GIF" style="max-width: 100%; height: auto; width: 1000px;">
</div>


## Updates 📰

- **[2024.12]** - We have released our **PIAD-C** and **LASO-C** datasets on Hugging Face! 🎉📂

## Getting Started 🚀


To be updated.